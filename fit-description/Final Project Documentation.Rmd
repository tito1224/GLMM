---
title: "Final Project Documentation"
author: "Angela Zheng and Oluwatitomi Adebajo"
date: "19/12/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
This document summarizes the various algorithms that the GLMM package uses in order to provide a solution to the research questions involved with the `epilepsy.csv` data set. More specifically, we would like to determine whether the drug Progabide significantly reduce the number of seizures a patient experiences after accounting for age. Notably, each function within the package serves as its own algorithm to aid in making likelihood-based inferences towards understanding the Poisson GLMM's fit to the data. 

## Maximum Likelihood Inferences
### Linear Predictor Form 
The model used in this package takes on the following form: 

\[
    \mu_i = \text{exp}(\beta_0 + \beta_1x_{1i} + \beta_2x_{2i}x_{3i} + \beta_3x_3i + Z_i)
\]

where $\beta_1$ is the predictor for **age**, $\beta_2$ is the predictor for the interaction between **expind** and **treat**,  $\beta_3$ is the predictor for **expind**, and $Z_i$ represents the random effect. $\beta_2$ represents the effect of the drug that is administered \textit{during} the clinical trial. As such, we are interested in testing whether there is significant interaction between the drug and the measurement period.

### Parameter Estimates
The algorithm within **estimation_functions.R** uses the `run_model()` function to find the estimates for $\beta_0$, the $\hat{\beta}$'s, $\hat{\sigma}^2$, the $Z_i$'s, and the t-test statistics for each $\beta$ predictor. As a result, `run_model()` outputs a printed summary that is similar to functions such as `lm()` and `summary.lm()`. The point estimates for $\beta_0$ and $\hat{\sigma}^2$ are based on the expressions derived where:

$$\hat{\beta}_0=-log\left(\frac{-n}{\sum_{i=1}^n\sum_{j=1}^k(y_{ij}e^{-x_i\beta})e^{Z_i^{(t)}}}\right)$$

and 

$$\hat{\sigma}^2=\frac{\sum_{i=1}^n{Z_i^2}^{(t)}}{n}$$
However, since the other outputted features of `run_model()` cannot be computed analytically such as the point estimates for the $\beta$'s, the random effects $Z_i$'s, and the t-test statistics for each $\beta$, it is simpler to just use the existing R function `glmer()` from the lme4 package to find these values.

### Standard Errors
The standard errors for the parameter estimates are calculated in the **bootstrapSE.R** file with a function called `btsp()`. This function is based on the following parametric bootstrapping algorithm:

1. Randomly simulate a set of $\hat{z_i}$ value using the estimate of $\hat{\sigma}^2$ from `run_model()`'s output (based on fitting the model to the cleaned `epilepsy` data set) which includes the `sigmasq` component
    + This step uses the `rnorm()` function to randomly generate values since we know that $Z_i \sim N(0,\sigma^2)$

2. Compute $\mu_i$ now that we have all the estimates $\hat{beta_0}$, $\beta$, and $z_i$ using the equation where $\mu_i=\text{exp}(\beta_0 + \beta_1x_{1i} + \beta_2x_{2i}x_{3i} + \beta_3x_{3i} + Z_i)$
    + This step uses the $z_i$ values from Step 1 as well as the $\hat{\beta_0}$ and $\beta$ estimates obtained from`run_model()`'s `beta` component  
    
3. Simulate an entirely new set of $Y_{ij}$ values now that we have the computed $\mu_i$ from Step 2
    + This step uses the `rpois()` function to randomly generate values since we know that $Y_{ij}\sim \text{Poisson}(\mu_i)$  
    
4. Input the simulated data of $Y_{ij}$ values into the `run_model()` function where the point estimates can be returned and stored  

5. Repeat Steps 1 to 4 using the `replicate()` function *B* times which is the value that the user passes to the function to indicate the number of bootstrap replications

Consequently, this bootstrapping algorithm will compute the standard errors for all parameters using the `sd()` function based on each parameter's samples of size *B*.

One consideration to keep in mind is that because the number of seizures range largely from 0 to 302 in the data set, there are instances when the model cannot converge when the simulated data is used. Since we cannot trust the estimates if the model did not converge, the `btsp()` function ensures that those estimates are not used in the final computation of the standard errors, in order to preserve accuracy. 

### Confidence Intervals
The confidence intervals utilize the point estimates from the `run_model()` function as well as the standard errors from the `btsp()` function. The function to implement confidence intervals are found in the **confidenceIntervals.R** file and this algorithm is implemented within the `ci()` function. The confidence intervals for the $\beta_0$, $\beta$, and $\sigma^2$ estimates are based on the following expressions:

$$\text{C.I for }\beta_0=\hat{\beta_0}\pm 1.96(SE(\hat{\beta_0}))$$
and

$$\text{C.I for }\beta=\hat{\beta}\pm 1.96(SE(\hat{\beta}))$$
and

$$\text{C.I for }\sigma^2=\left[\frac{(n-1)\hat{\sigma}^2}{\chi^2_{\alpha/2,n-1}},\frac{(n-1)\hat{\sigma}^2}{\chi^2_{1-\alpha/2,n-1}}\right]$$

Therefore, `ci()` calls on the `run_model()` and `btsp()` functions to save the parameters' point estimates and standard errors respectively, and then computes the confidence intervals based on the expressions above for $\beta_0$, $\beta$, and $\sigma^2$.

## Hypothesis Testing
The fitting of the model is used to answer research questions about the data set. We are interested in whether the drug significantly reduces the number of seizures a patient experiences after accounting for age. That means we need to find the effect of the interaction between the two treatment groups and the two periods of measurement. Specifically, we must look at the interaction between **treat** and **expind** within the `epilepsy.csv` data. The predictor for this interaction, denoted as $\beta_2$, can be tested with the following statement:

$$H_0: \beta_2 = 0$$
$$H_a: \beta_2 < 0$$

This research question requires a t-test based on the Student's t-distribution. The hypothesis test is fairly simple with the use of the `run_model()` function, as one of its components already includes `test_stat`. This is the t-test statistic, denoted by $t^*$, which is then tested against the critical value, denoted by $t_{\alpha,n-1}$. This can be rewritten as $P(t^*<t_{\alpha,n-1})$. A common significance level of $\alpha=0.05$ can be used to conduct this test.

To find the critical value $t_{\alpha,n-1}$, we can use the `qt()` function. If the test statistic for the interaction predictor between **expind** and **treat** is less than the critical value, reject the null hypothesis and assume that the alternative hypothesis is true. Otherwise, do not reject the null hypothesis. 

If the null hypothesis, $H_0$, is true, this is equivalent to the claim that the drug does *not* significantly reduce the number of seizures a patient experiences. In other words, the drug does not have an effect on the subjects. If the alternative hypothesis, $H_a$, is true, this is equivalent to the claim that the drug does significantly reduce the number of seizures a patient experiences.

## Conclusion
Based on the results mentioned in the vignette, the test statistic was not less than the critical value, hence we failed to reject the null hypothesis. However, one thing to take note of is that there were outliers in the number of seizures seen in the data. Outliers tend to increase the estimated standard errors, which also reduces the value of the test statistic, computed using $t^* = \frac{\hat{\beta_2}-0}{SE(\hat{\beta_2})}$. This is important because a smaller test statistic allows for a greater chance to reject the null hypothesis.

Running all the algorithms mentioned in this document has resulted in statistical evidence to reject the null hypothesis and conclude the drug is not effective. However, given that the value of the test statistic is so close to the critical value, we suggest that more data is gathered in order to draw more conclusive results about the effectiveness of the drug.
